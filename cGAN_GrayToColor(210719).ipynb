{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cGAN_GrayToColor(210719).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNCmRbtvSewgKfV6gVE7D9/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yohan0358/Study_GAN/blob/main/cGAN_GrayToColor(210719).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-TcITBwp56f"
      },
      "source": [
        "[reference : 가짜연구소](https://pseudo-lab.github.io/Tutorial-Book/chapters/GAN/Ch3-GAN.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD9UxAxMp73_"
      },
      "source": [
        "!git clone https://github.com/Pseudo-Lab/Tutorial-Book-Utils\n",
        "!python Tutorial-Book-Utils/PL_data_loader.py --data GAN-Colorization\n",
        "!unzip -q Victorian400-GAN-colorization-data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U25ttEZ4qDLY"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.utils import make_grid\n",
        "\n",
        "import time\n",
        "\n",
        "import cv2\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOPBCqyMst-w"
      },
      "source": [
        "path_origin = './original/'\n",
        "path_gray = './gray/'\n",
        "path_resized = './resized/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR5AM9CUs1mE"
      },
      "source": [
        "_origin = sorted(glob.glob(path_origin + '*'))\n",
        "_gray = sorted(glob.glob(path_gray + '*'))\n",
        "_resized = sorted(glob.glob(path_resized + '*'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVKgY5FZtd4X"
      },
      "source": [
        "data = [_origin, _gray, _resized]\n",
        "\n",
        "for d in data:\n",
        "    print(cv2.imread(d[0]).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtXE_3e0uH6y"
      },
      "source": [
        "def plot_img(img):\n",
        "    img = cv2.imread(img)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    plt.imshow(img)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSX5By4su1B5"
      },
      "source": [
        "for d in [_origin, _gray, _resized]:\n",
        "    plot_img(d[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIqjfOwIu3DP"
      },
      "source": [
        "def get_mean_std(file):\n",
        "    mean = 0\n",
        "    img_list = []\n",
        "    for img in file:\n",
        "        img = cv2.imread(img)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) / 255\n",
        "        img_list.append(img)\n",
        "        mean += img.reshape(-1, 3).mean(axis = 0) / len(file)\n",
        "\n",
        "    var = 0\n",
        "    for img in img_list:\n",
        "        var += ((img.reshape(-1, 3) - mean) ** 2).mean(axis = 0) / len(file)\n",
        "    std = var ** 0.5\n",
        "\n",
        "    return mean, std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRAsK2J-nfu4"
      },
      "source": [
        "# dataset load\n",
        "class Custom_dataset(Dataset):\n",
        "    def __init__(self, color_path, gray_path, color_transform, gray_transform):\n",
        "        super(Custom_dataset, self).__init__()\n",
        "        \n",
        "        self.color_file = color_path\n",
        "        self.gray_file = gray_path\n",
        "\n",
        "        self.color_transform = color_transform\n",
        "        self.gray_transform = gray_transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.color_file)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        gray_img = Image.open(self.gray_file[idx]).convert('RGB')\n",
        "        color_img = Image.open(self.color_file[idx]).convert('RGB')\n",
        "\n",
        "        gray_img = self.gray_transform(gray_img)\n",
        "        color_img = self.color_transform(color_img)\n",
        "\n",
        "        return gray_img, color_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoNcOumUvYkz"
      },
      "source": [
        "color_mean, color_std = get_mean_std(_resized)\n",
        "gray_mean, gray_std = get_mean_std(_gray)\n",
        "\n",
        "color_transform = transforms.Compose([\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize(mean = color_mean, std = color_std)  \n",
        "                                    ])\n",
        "\n",
        "gray_transform = transforms.Compose([\n",
        "                                     transforms.ToTensor(),\n",
        "                                     transforms.Normalize(mean = gray_mean[0], std = gray_std[0])\n",
        "                                    ])\n",
        "\n",
        "dataset = Custom_dataset(_resized, _gray, color_transform, gray_transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7XuvdpUvoXw"
      },
      "source": [
        "batch_size = 16\n",
        "loader = DataLoader(dataset, batch_size, shuffle= True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPSHCOgayKZ_"
      },
      "source": [
        "def imshow_grid(img, mean, std):\n",
        "    img = make_grid(img.cpu().detach())\n",
        "    np_img = np.transpose(img.numpy(), (1,2,0))\n",
        "    np_img = np_img * std + mean\n",
        "    np_img = np.clip(np_img, 0, 1)\n",
        "\n",
        "    plt.figure(figsize = (10, 4))\n",
        "    plt.imshow(np_img)\n",
        "    plt.show()\n",
        "\n",
        "sample_g, sample_c = next(iter(loader))\n",
        "\n",
        "imshow_grid(sample_g, gray_mean, gray_std)\n",
        "imshow_grid(sample_c, color_mean, color_std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtXoFw2nyY_i"
      },
      "source": [
        "# 256 x 256 이미지 생성\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(2, 64, 4, 2, 1, bias = False),\n",
        "            nn.LeakyReLU(0.2,),\n",
        "            self._conv_block(64, 128),\n",
        "            self._convT_block(128, 64),\n",
        "            nn.Conv2d(64, 3, 3, 1, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def _conv_block(self, in_ch, out_ch, kernel_size = 3, stride = 1, padding = 1):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias = False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def _convT_block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        return x\n",
        "\n",
        "'''\n",
        "noise : (batch, 100, 1, 1) -> (batch, 1, 256, 256)\n",
        "img   :                       (batch, 1, 256, 256)   \n",
        "==> (batch, 2, 256, 256) 으로 만드는 generator, 학습시간이 너무 오래걸리고 성능 x\n",
        "\n",
        "'''\n",
        "# class Generator(nn.Module):\n",
        "#     def __init__(self, latent):\n",
        "#         super(Generator, self).__init__()\n",
        "\n",
        "#         self.noise_up = nn.Sequential(\n",
        "#             nn.ConvTranspose2d(latent, 512, 8, 1, 0),\n",
        "#             nn.LeakyReLU(0.2),\n",
        "#             self._convT_block(512, 256),\n",
        "#             self._convT_block(256, 128),\n",
        "#             self._convT_block(128, 64),\n",
        "#             self._convT_block(64, 32),\n",
        "\n",
        "#         )\n",
        "\n",
        "#         self.img_down = nn.Sequential(\n",
        "#             nn.Conv2d(1, 32, 4, 2, 1),\n",
        "#             nn.LeakyReLU(0.2),\n",
        "#             # nn.MaxPool2d((2,2))\n",
        "#         )\n",
        "\n",
        "#         self.conv = nn.Sequential(\n",
        "#             self._convT_block(64, 128),\n",
        "#             self._conv_block(128, 128, 3, 1, 1),\n",
        "#             self._conv_block(128, 64, 3, 1, 1),\n",
        "#             nn.Conv2d(64, 3, 3, 1, 1),\n",
        "\n",
        "#             nn.Tanh()            \n",
        "#         )\n",
        "\n",
        "#     def _convT_block(self, in_ch, out_ch):\n",
        "#         return nn.Sequential(\n",
        "#             nn.ConvTranspose2d(in_ch, out_ch, 4, 2, 1),\n",
        "#             nn.BatchNorm2d(out_ch),\n",
        "#             nn.LeakyReLU(0.2)\n",
        "#         )\n",
        "\n",
        "#     def _conv_block(self, in_ch, out_ch, kernel_size = 4, stride = 2, padding = 1):\n",
        "#         return nn.Sequential(\n",
        "#             nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding),\n",
        "#             nn.BatchNorm2d(out_ch),\n",
        "#             nn.LeakyReLU(0.2)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, img, z):\n",
        "#         img = self.img_down(img)\n",
        "#         z = self.noise_up(z)\n",
        "#         x = torch.cat([img, z], dim = 1)\n",
        "#         x = self.conv(x)\n",
        "#         return x\n",
        "\n",
        "def test():\n",
        "    G = Generator()\n",
        "    img = torch.randn(4, 1, 256, 256)\n",
        "    z = torch.randn(4, 1, 256, 256)\n",
        "    x = torch.cat([img, z], dim = 1)\n",
        "    out = G(x)\n",
        "    print(out.shape)\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fisz4pIc_9Ip"
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, image_channel = 3):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Conv2d(image_channel, 64, 4, 2, 1, bias= False),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            self._block(64, 128),\n",
        "            self._block(128, 256),\n",
        "            self._block(256, 512),\n",
        "            self._block(512, 512),\n",
        "            self._block(512, 256),\n",
        "            self._block(256, 128),\n",
        "\n",
        "            nn.Conv2d(128, 1, 4, 2, 1, bias = False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def _block(self, in_ch, out_ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 4, 2, 1, bias = False),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU(0.2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)\n",
        "        return x.squeeze()\n",
        "\n",
        "def test():\n",
        "    D = Discriminator()\n",
        "    x = torch.randn(16, 3, 256, 256)\n",
        "    print(D(x).shape)\n",
        "\n",
        "test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_77YFslFplwz"
      },
      "source": [
        "def weight_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.01)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LnIMLAACfQH"
      },
      "source": [
        "# hyper parameter\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device :', device)\n",
        "\n",
        "lr = 2e-4\n",
        "epochs = 50\n",
        "latent = 256\n",
        "img_size = 256\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)\n",
        "\n",
        "weight_init(G)\n",
        "weight_init(D)\n",
        "\n",
        "G_optim = optim.Adam(G.parameters(), lr = lr)\n",
        "D_optim = optim.Adam(D.parameters(), lr = lr)\n",
        "\n",
        "# L2 Losss\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "def generate_noise(batch_size, latent):\n",
        "    z = torch.randn(batch_size, 1, latent, latent)\n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuUZm4NCDgRO"
      },
      "source": [
        "G.train()\n",
        "D.train()\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    D_losses = 0\n",
        "    G_losses = 0\n",
        "\n",
        "    t = time.time()\n",
        "    for i, (img_g, img_c) in enumerate(loader):\n",
        "        batch_size = len(img_g)\n",
        "\n",
        "        img_g, img_c = img_g[:, 0:1, :, :].to(device), img_c.to(device)\n",
        "\n",
        "        # Discriminator 학습\n",
        "        real_labels = torch.ones(batch_size, img_size).to(device)\n",
        "        fake_labels = torch.zeros(batch_size, img_size).to(device)\n",
        "\n",
        "        z = generate_noise(batch_size, latent).to(device)\n",
        "        z = torch.cat([img_g, z], dim = 1)\n",
        "\n",
        "        output_z = D(G(z))\n",
        "        output_img = D(img_c)\n",
        "\n",
        "        D_loss = torch.mean((output_img - 1) ** 2) + torch.mean(output_z ** 2)\n",
        "\n",
        "        D_optim.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_optim.step()\n",
        "\n",
        "        # Generator 학습\n",
        "        fake_img = G(z)\n",
        "        output = D(fake_img)\n",
        "        G_loss = torch.mean((output - 1 ) **2 )\n",
        "\n",
        "        G_optim.zero_grad()\n",
        "        G_loss.backward()\n",
        "        G_optim.step()\n",
        "\n",
        "        D_losses += D_loss.item() / len(loader)\n",
        "        G_losses += G_loss.item() / len(loader)\n",
        "\n",
        "    print(f'[{epoch + 1} / {epochs}] epochs \\t D_loss : {D_losses:.4f} \\t G_loss : {G_losses:.4f} \\t time : {time.time() - t}')\n",
        "    \n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        G.eval()\n",
        "\n",
        "        z = generate_noise(batch_size, latent).to(device)\n",
        "        z = torch.cat([img_g, z], dim = 1)\n",
        "        print('====== GRAY ======')\n",
        "        imshow_grid(img_g, gray_mean, gray_std)\n",
        "        print('====== COLOR ======')\n",
        "        imshow_grid(img_c, color_mean, color_std)\n",
        "        output = G(z)\n",
        "        print('====== FAKE ======')\n",
        "        imshow_grid(output, color_mean, color_std)\n",
        "\n",
        "        G.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ3vSEFyso0p"
      },
      "source": [
        "# 모델 저장\n",
        "torch.save(G.state_dict(), 'G.ckpt')\n",
        "torch.save(D.state_dict(), 'D.ckpt')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}